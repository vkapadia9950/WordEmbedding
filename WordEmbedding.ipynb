{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordEmbedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ3zTkqt1jgu"
      },
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mPdvP5T1oyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11818118-c59e-46a7-d02a-1ce695845037"
      },
      "source": [
        "#Loading the Dataset\n",
        "embedding= hub.load (\"https://tfhub.dev/google/Wiki-words-250/2\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 35 calls to <function recreate_function.<locals>.restored_function_body at 0x7f72d81f6c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 35 calls to <function recreate_function.<locals>.restored_function_body at 0x7f72d81f6c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 36 calls to <function recreate_function.<locals>.restored_function_body at 0x7f72d81fa320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 36 calls to <function recreate_function.<locals>.restored_function_body at 0x7f72d81fa320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gefHm6erb3wO",
        "outputId": "6158c000-4e01-4948-c69e-027a124e596a"
      },
      "source": [
        "# Embedding king, man, woman, queen\n",
        "a = embedding ([\"king\"])\n",
        "b = embedding ([\"man\"])\n",
        "c = embedding ([\"woman\"])\n",
        "d = embedding ([\"queen\"])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f72d81f1e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:8 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f72d81f1e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7P6raDQb98V",
        "outputId": "cbf93ed4-f4b0-438f-a32e-725e8ff0cdf7"
      },
      "source": [
        "# Storing the result ofvector(king) − vector(man) + vector(woman)\n",
        "X= a-b+c\n",
        "print(\"king-man+woman:\", [X])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "king-man+woman: [<tf.Tensor: shape=(1, 250), dtype=float32, numpy=\n",
            "array([[-0.12994584, -0.17411731,  0.08241335, -0.09460426, -0.02963368,\n",
            "         0.00833852, -0.01580581, -0.07200217, -0.0374763 , -0.01857486,\n",
            "         0.04575163, -0.06350955,  0.0310036 ,  0.04439414,  0.06356907,\n",
            "        -0.02856771,  0.05558529,  0.07249814, -0.02398837,  0.0455301 ,\n",
            "        -0.07038731,  0.00989324, -0.05211002, -0.02339969, -0.10386609,\n",
            "        -0.00747646, -0.0174827 , -0.15109651, -0.16803886, -0.03159868,\n",
            "        -0.04374632,  0.0941674 ,  0.05635576, -0.11544351, -0.01706913,\n",
            "        -0.0181496 ,  0.05560432,  0.01284544, -0.09410097,  0.08030569,\n",
            "        -0.13458134, -0.12798919, -0.14993384,  0.06665589,  0.07577673,\n",
            "        -0.12577374, -0.06869593, -0.10468247, -0.01054525, -0.07139292,\n",
            "        -0.00569897, -0.02220746, -0.11851092, -0.09434773,  0.06391967,\n",
            "         0.04567089,  0.14339279, -0.13938236, -0.03750862,  0.03229091,\n",
            "         0.07670465,  0.05507568, -0.01978571,  0.0488369 ,  0.06290312,\n",
            "        -0.02575352, -0.04922489,  0.03056283, -0.07172222,  0.06982613,\n",
            "         0.0803801 , -0.04973414, -0.02608817,  0.02759914,  0.002708  ,\n",
            "        -0.05333981,  0.03711914, -0.09599224,  0.03230607, -0.02972047,\n",
            "        -0.0615705 , -0.06141805,  0.17323463, -0.04320083, -0.07951543,\n",
            "        -0.02547963, -0.06859723, -0.01553594, -0.04165017,  0.02113948,\n",
            "         0.07423727, -0.07921132, -0.01724075, -0.05560023,  0.06555721,\n",
            "         0.05268419, -0.0192046 , -0.0866887 ,  0.01040605,  0.08001635,\n",
            "         0.05380156,  0.1543872 , -0.02615696,  0.07417218, -0.20474243,\n",
            "         0.11950888, -0.1324215 ,  0.00879025,  0.00739774,  0.06482171,\n",
            "         0.01035097,  0.03585192, -0.10165727,  0.11948258, -0.08690634,\n",
            "         0.02516122, -0.05741835,  0.01614384, -0.0519414 , -0.00041243,\n",
            "         0.08684582,  0.04555257, -0.02207289, -0.02609378,  0.10907193,\n",
            "        -0.04955634, -0.05254844, -0.01550413,  0.00133016,  0.04234105,\n",
            "         0.07710397, -0.0439746 ,  0.04601943, -0.05255038,  0.16154867,\n",
            "        -0.01456506,  0.02098858, -0.03760958, -0.05088559, -0.15935194,\n",
            "         0.12163188, -0.06758945, -0.01911313, -0.01079746,  0.02780328,\n",
            "        -0.08232888, -0.04015777,  0.07017996,  0.02528294,  0.06738663,\n",
            "        -0.00742915, -0.0701405 , -0.06927051,  0.11858883,  0.01074681,\n",
            "        -0.06430183,  0.07137705, -0.04360432,  0.01252709, -0.02756085,\n",
            "         0.04253813, -0.05186563,  0.06491366, -0.0356636 , -0.02376426,\n",
            "        -0.02842608, -0.06913847,  0.06751455,  0.14509952, -0.01843431,\n",
            "        -0.05114117, -0.01097725, -0.03928608, -0.02968133, -0.00317439,\n",
            "         0.02707167, -0.13780919,  0.01633139,  0.07788566,  0.01345414,\n",
            "        -0.04022622, -0.05141499, -0.00484858,  0.02714027,  0.05863062,\n",
            "         0.00706645, -0.06936499,  0.08888212, -0.03058738, -0.08569148,\n",
            "        -0.07521473, -0.02533121, -0.21343365, -0.08270675, -0.08997436,\n",
            "        -0.02867441, -0.00746529, -0.03505145, -0.01891331,  0.01864205,\n",
            "        -0.05430565,  0.11990292, -0.01086501,  0.00871192,  0.03589291,\n",
            "         0.00432714,  0.02932635,  0.01359615, -0.08351292, -0.08115736,\n",
            "         0.04097844, -0.02255999, -0.04587416, -0.04101024, -0.06847794,\n",
            "        -0.06374119,  0.05628698,  0.00374963, -0.02684985,  0.0231915 ,\n",
            "         0.03232276,  0.09758668, -0.01291919,  0.06886382,  0.04873909,\n",
            "         0.07173714,  0.07715012,  0.11576906,  0.07526608,  0.02519506,\n",
            "        -0.13528627, -0.00261188, -0.02652643, -0.04245754, -0.07537253,\n",
            "        -0.04215054,  0.01132629,  0.0033743 ,  0.00175655,  0.10029789,\n",
            "         0.02301757,  0.04389887,  0.0325456 ,  0.10542942,  0.05422645,\n",
            "         0.02636919,  0.16428472,  0.07135022, -0.02868139, -0.04592651]],\n",
            "      dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT9eZd3FcWaC",
        "outputId": "db1abad7-ee7e-4147-9cbc-0e26e058a43d"
      },
      "source": [
        "# Storing the result of vector(king) − vector(man) + vector(queen) to find similarity of woman\n",
        "Y= b-a+d\n",
        "print(\"man-king+queen:\", [Y])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "man-king+queen: [<tf.Tensor: shape=(1, 250), dtype=float32, numpy=\n",
            "array([[ 0.01681516, -0.08521656, -0.06851303,  0.0595478 , -0.10875496,\n",
            "         0.10709716,  0.03006158, -0.02443278, -0.01117055, -0.11209973,\n",
            "         0.05852605,  0.07159583,  0.07165094,  0.14366794, -0.01810386,\n",
            "        -0.15666823,  0.07434727,  0.05848619, -0.02905447, -0.02952485,\n",
            "         0.10458523, -0.00647739,  0.04915919, -0.05695554, -0.0138592 ,\n",
            "         0.0461482 ,  0.10628796,  0.13474749,  0.03000064,  0.19051257,\n",
            "         0.12343374,  0.02059592,  0.12196557, -0.11266758, -0.07886181,\n",
            "        -0.08491204, -0.03072942,  0.03749049,  0.11240648, -0.04657238,\n",
            "         0.03493292, -0.1225394 , -0.04957216, -0.03854577,  0.11260201,\n",
            "        -0.01066366, -0.19665536,  0.08780457, -0.08849054, -0.03091501,\n",
            "         0.03170084,  0.03101998, -0.05169848,  0.125536  , -0.02303532,\n",
            "        -0.02656888, -0.00692867, -0.05032928,  0.11097574,  0.02092209,\n",
            "        -0.10292269, -0.05135739, -0.09984776,  0.08508724,  0.01422701,\n",
            "        -0.06265945, -0.11912451,  0.0460498 , -0.07058955, -0.0263464 ,\n",
            "         0.06257766, -0.00520236,  0.12482406, -0.0305562 ,  0.13499404,\n",
            "         0.09055759, -0.0763118 ,  0.07715398,  0.109127  , -0.0007191 ,\n",
            "        -0.04739648,  0.03181424, -0.12663814,  0.05471291, -0.18555823,\n",
            "         0.02938213, -0.14057492, -0.13215104, -0.11929085,  0.0169861 ,\n",
            "        -0.09915593,  0.00647098, -0.06431836, -0.05457412,  0.02208921,\n",
            "         0.04338772, -0.0818008 , -0.04996958,  0.04620631, -0.00961853,\n",
            "         0.02114771,  0.08897088,  0.10740931,  0.09841879, -0.01406644,\n",
            "         0.01559999, -0.12526464,  0.02205179, -0.04238557,  0.02408355,\n",
            "        -0.06547627,  0.12326334, -0.04371411,  0.0817517 , -0.09969302,\n",
            "        -0.0262796 ,  0.06515457, -0.31890365, -0.00653272,  0.1074459 ,\n",
            "        -0.0613341 ,  0.04106341,  0.10464001, -0.01026322,  0.04995075,\n",
            "        -0.13807975, -0.08283035,  0.15269338,  0.01239116,  0.04706788,\n",
            "        -0.15363325,  0.04414944, -0.15098289, -0.04850304, -0.11467765,\n",
            "         0.08062035,  0.0036255 , -0.0833209 , -0.07675062, -0.01488908,\n",
            "        -0.01117676,  0.13002293, -0.0068622 ,  0.07352088,  0.10407716,\n",
            "        -0.03650039, -0.13680407,  0.02061035, -0.07178798,  0.07412884,\n",
            "         0.03319114, -0.13064384, -0.00116394, -0.06885958,  0.1303646 ,\n",
            "         0.07366655,  0.04637082, -0.17434244, -0.08520648, -0.05595769,\n",
            "        -0.07463813, -0.04196825, -0.13196856, -0.19904123,  0.0315065 ,\n",
            "         0.05040962, -0.01874494,  0.05498406, -0.0435516 ,  0.15234676,\n",
            "         0.07316467, -0.02995591, -0.09404084,  0.07033846, -0.05925226,\n",
            "        -0.13543156, -0.00297358, -0.04782364, -0.01855819,  0.0715757 ,\n",
            "         0.09738925,  0.06326593,  0.10574774, -0.02570614,  0.18765974,\n",
            "        -0.03001709,  0.05458944,  0.06828144, -0.07593486, -0.05688392,\n",
            "        -0.12538192, -0.13137563,  0.01291358, -0.08053659, -0.00515433,\n",
            "        -0.01194938,  0.00101613, -0.09161125, -0.0257626 , -0.11054204,\n",
            "        -0.02171385, -0.19964698, -0.01335135, -0.10581016, -0.00339731,\n",
            "        -0.07011034,  0.02924129,  0.0582071 ,  0.02013226, -0.0361151 ,\n",
            "        -0.05823991,  0.06924165,  0.14155261, -0.16176085,  0.11452322,\n",
            "        -0.01053724, -0.02675857,  0.0601933 ,  0.02060938,  0.07990132,\n",
            "        -0.02731281,  0.13985178,  0.03551794,  0.01052809,  0.00040614,\n",
            "         0.04026143,  0.01520441,  0.01636688, -0.05463767, -0.07409278,\n",
            "        -0.038071  , -0.18201435, -0.08203804,  0.05068638,  0.02035294,\n",
            "         0.07069936,  0.17978522,  0.03417282,  0.01693006,  0.12496585,\n",
            "        -0.05078956,  0.02182364, -0.03064463,  0.08682808,  0.04437024,\n",
            "        -0.06710461, -0.05618909, -0.02262753,  0.01286339,  0.01015137]],\n",
            "      dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kvXb17GdmE9",
        "outputId": "7aaf11ee-8526-4eeb-90ff-89993b2edeba"
      },
      "source": [
        "#Calculating the Cosine Similarity between Vectors of Words.\n",
        "\n",
        "print(\"Similarity between king-man+woman and queen:\",cosine_similarity(X,d))\n",
        "print(\"Similarity between man-king+queen and woman:\",cosine_similarity(Y,c))\n",
        "print(\"Similarity between man and woman:\",cosine_similarity(b,c))\n",
        "print(\"Similarity between king and queen:\",cosine_similarity(a,d))\n",
        "print(\"Similarity between man and king:\",cosine_similarity(b,a))\n",
        "print(\"Similarity between woman and queen:\",cosine_similarity(c,d))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity between king-man+woman and queen: [[0.763873]]\n",
            "Similarity between man-king+queen and woman: [[0.83955884]]\n",
            "Similarity between man and woman: [[0.8381338]]\n",
            "Similarity between king and queen: [[0.71021986]]\n",
            "Similarity between man and king: [[0.36127636]]\n",
            "Similarity between woman and queen: [[0.5902161]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZXHh_XD1xFh"
      },
      "source": [
        "# Embedding Paris, France, Italy, Rome\n",
        "a1 = embedding ([\"Paris\"])\n",
        "b1 = embedding ([\"France\"])\n",
        "c1 = embedding ([\"Italy\"])\n",
        "d1 = embedding ([\"Rome\"])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxvlA29v19zy",
        "outputId": "8be183da-b9ed-4de0-878e-ce4fd6367bd1"
      },
      "source": [
        "# Storing the result ofvector(Paris) − vector(France) + vector(Italy)\n",
        "X1= a1-b1+c1\n",
        "print(\"Paris-France+Italy:\", [X1])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Paris-France+Italy: [<tf.Tensor: shape=(1, 250), dtype=float32, numpy=\n",
            "array([[-7.06323236e-03,  1.06687166e-01,  7.31521240e-03,\n",
            "         5.26041798e-02,  1.89695656e-02,  8.40932727e-02,\n",
            "         8.83067027e-04,  1.10935658e-01, -5.20010255e-02,\n",
            "        -1.41617298e-01, -5.03391251e-02, -6.35691136e-02,\n",
            "        -7.17586428e-02, -8.52132309e-03,  1.04058161e-01,\n",
            "        -5.06601781e-02, -3.47199142e-02,  1.35877831e-02,\n",
            "        -4.24716696e-02,  9.08860378e-03,  5.71915954e-02,\n",
            "        -2.70423815e-02, -3.47405560e-02, -2.06796005e-02,\n",
            "        -1.00331597e-01, -2.99576633e-02,  4.90206629e-02,\n",
            "         2.33950149e-02, -1.65568106e-02,  6.71938285e-02,\n",
            "         1.33611009e-01,  3.93283181e-02,  9.12448168e-02,\n",
            "        -4.95099053e-02, -2.55508367e-02,  2.51908898e-02,\n",
            "        -4.23668697e-02,  1.20001487e-01,  6.35651350e-02,\n",
            "        -3.00902147e-02, -5.18453941e-02,  4.50439677e-02,\n",
            "         2.86682546e-02, -8.11181217e-03, -2.34579779e-02,\n",
            "        -8.82764161e-02,  3.76700796e-02,  6.53538257e-02,\n",
            "        -4.66737486e-02, -1.40183002e-01,  9.15279537e-02,\n",
            "         4.09593433e-02, -3.86301801e-02, -2.37153657e-02,\n",
            "        -4.99426089e-02, -1.98257156e-03,  3.71754952e-02,\n",
            "         6.18365966e-02, -1.98042542e-02,  4.26397007e-03,\n",
            "        -5.53840064e-02,  8.30736011e-03, -1.17055140e-02,\n",
            "         1.89484209e-02,  2.38313545e-02,  4.35067676e-02,\n",
            "        -9.54274684e-02,  1.30151004e-01, -2.11294726e-01,\n",
            "         9.87673178e-03,  4.35578115e-02, -5.50615713e-02,\n",
            "         5.38678542e-02, -1.50081098e-01, -5.15536442e-02,\n",
            "         5.13427742e-02,  1.40104577e-01, -1.14806205e-01,\n",
            "         2.90933158e-02, -1.40957832e-02,  2.98082642e-02,\n",
            "        -1.06255516e-01,  1.07596621e-01,  6.78674132e-02,\n",
            "         1.07083097e-02, -6.72159195e-02, -7.26269335e-02,\n",
            "        -7.14520589e-02, -9.66995656e-02,  1.34697417e-02,\n",
            "         7.19352961e-02,  5.09557053e-02, -2.32303143e-03,\n",
            "         4.05692868e-02,  6.05746843e-02,  7.00689405e-02,\n",
            "        -6.05442375e-02, -7.48676956e-02,  7.95703474e-03,\n",
            "        -2.93549299e-02, -8.97088200e-02,  5.67197502e-02,\n",
            "         9.51394439e-02, -6.56934679e-02,  1.11600347e-01,\n",
            "        -6.76309317e-03,  2.10986007e-02, -3.83759104e-02,\n",
            "        -2.58951150e-02, -8.72180611e-03,  9.59335715e-02,\n",
            "         9.22792032e-03, -8.00583363e-02, -7.91320130e-02,\n",
            "        -3.56906392e-02,  7.78795499e-03,  9.00069699e-02,\n",
            "        -1.17815286e-03,  1.08012043e-01,  8.47778171e-02,\n",
            "        -9.22200829e-02,  3.86149883e-02,  7.44278878e-02,\n",
            "         9.79267955e-02, -1.42180473e-02, -2.97232587e-02,\n",
            "        -5.46021871e-02,  5.35743088e-02, -1.40753418e-01,\n",
            "        -4.92590331e-02,  1.14218220e-01,  8.20822865e-02,\n",
            "         5.27628697e-02,  1.80802494e-01, -3.60599980e-02,\n",
            "         2.89779976e-02, -4.57112789e-02, -4.21544425e-02,\n",
            "        -1.41166095e-02, -4.20855582e-02, -1.41724199e-02,\n",
            "         7.07656331e-03,  5.60717657e-02, -4.97139320e-02,\n",
            "         9.86166224e-02, -1.04896940e-01, -4.38223854e-02,\n",
            "         1.22886598e-01, -1.26782581e-02,  1.17211819e-01,\n",
            "         1.93270277e-02, -9.22283828e-02, -1.06537953e-01,\n",
            "        -8.00742395e-03,  2.32618935e-02, -5.00279739e-02,\n",
            "        -8.97651538e-02, -8.07869434e-02, -5.10520339e-02,\n",
            "         2.53565088e-02,  3.58533114e-03,  1.10751972e-01,\n",
            "        -5.82015179e-02, -3.89875472e-03,  1.03794895e-01,\n",
            "         1.29475847e-01, -2.63145622e-02, -2.54949909e-02,\n",
            "        -1.25205994e-01,  1.10737406e-01,  4.79398668e-03,\n",
            "         2.38774642e-02, -2.74644643e-02,  6.19572774e-02,\n",
            "         1.89539045e-04,  1.49866715e-01, -8.92391652e-02,\n",
            "        -1.97793394e-02,  1.04774967e-01,  1.33669209e-02,\n",
            "         2.88580880e-02, -9.56091434e-02, -2.76294015e-02,\n",
            "        -1.01363376e-01, -1.05008399e-02,  6.71833009e-02,\n",
            "        -2.86482945e-02,  4.29472663e-02,  6.26033992e-02,\n",
            "        -3.22215408e-02, -1.00028664e-02,  1.84543878e-02,\n",
            "         1.19763330e-01,  2.48217024e-02, -8.46644305e-03,\n",
            "         4.17350531e-02,  9.87544805e-02,  3.26441638e-02,\n",
            "        -4.30310741e-02,  1.45397231e-01,  5.41495308e-02,\n",
            "        -5.30399308e-02, -7.78583530e-03, -1.09588161e-01,\n",
            "        -1.02177732e-01, -8.93045217e-03,  3.51017714e-03,\n",
            "         6.26710355e-02,  5.11912629e-03,  5.65471351e-02,\n",
            "        -6.36477098e-02,  1.42763242e-01,  6.60515875e-02,\n",
            "         4.51820083e-02,  4.61503603e-02, -2.57746130e-02,\n",
            "        -1.76226735e-01, -4.00725380e-02, -2.32233815e-02,\n",
            "        -6.95910901e-02, -9.49207693e-02,  9.41285118e-03,\n",
            "        -6.75146058e-02, -2.38238052e-02,  2.96969134e-02,\n",
            "         1.10897887e-02, -4.35602814e-02, -3.34020471e-03,\n",
            "         6.03251085e-02,  2.54810061e-02, -1.22120991e-01,\n",
            "        -9.56351683e-03,  4.11808491e-04, -7.81194642e-02,\n",
            "         1.35852247e-02,  1.03474185e-01, -5.94189484e-03,\n",
            "        -5.99491969e-02,  3.22803184e-02, -7.58200958e-02,\n",
            "        -6.47436455e-02,  1.93954781e-02,  6.67227879e-02,\n",
            "         3.49471271e-02,  1.71959717e-02, -4.44262102e-03,\n",
            "        -8.94080251e-02, -8.57726485e-02,  1.92959234e-02,\n",
            "         4.54400852e-03]], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkK7QLctDRp7",
        "outputId": "16874c4a-ff07-4b76-9a75-8340a88afb69"
      },
      "source": [
        "# Storing the result of vector(Italy) − vector(Paris) + vector(Rome) to find similarity of France\n",
        "Y1= c1-a1+d1\n",
        "print(\"France-Paris+Italy:\", [Y1])\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "France-Paris+Italy: [<tf.Tensor: shape=(1, 250), dtype=float32, numpy=\n",
            "array([[ 9.65829194e-03,  1.50402617e-02,  1.02494225e-01,\n",
            "        -1.00866050e-01,  8.80958587e-02,  1.05187044e-01,\n",
            "         6.10304996e-05,  2.96332166e-02, -5.84375039e-02,\n",
            "        -1.01902559e-01, -1.64616495e-01,  5.78956306e-02,\n",
            "        -9.26014036e-02, -4.21449170e-03,  6.10140562e-02,\n",
            "        -5.25101498e-02, -7.38929734e-02, -7.87460618e-03,\n",
            "         5.91115579e-02,  7.67147541e-02,  1.26453459e-01,\n",
            "         1.92631781e-02, -5.01099937e-02,  4.42669168e-03,\n",
            "        -1.19286478e-02, -1.57005414e-02,  3.93925980e-02,\n",
            "        -3.14971022e-02,  1.62983984e-02,  1.34116039e-02,\n",
            "         1.74449310e-01,  9.30660814e-02,  1.13316759e-01,\n",
            "        -2.67461926e-01, -3.61998752e-03,  6.20473288e-02,\n",
            "        -1.06010437e-01,  2.00535893e-01, -1.60224549e-02,\n",
            "         8.48757476e-02, -6.62501752e-02,  7.14381933e-02,\n",
            "        -3.81751265e-03, -7.64440447e-02,  1.40486538e-01,\n",
            "        -5.22043556e-02,  2.32038066e-01, -1.41493082e-01,\n",
            "        -1.78438544e-01, -1.87382460e-01, -6.27768338e-02,\n",
            "         9.71368253e-02, -1.04472086e-01, -6.37172908e-02,\n",
            "         4.61939573e-02,  3.56253870e-02,  1.31467357e-01,\n",
            "        -5.81149794e-02,  1.78995475e-01, -1.53865218e-02,\n",
            "         3.21752653e-02,  5.85534051e-02, -6.81088716e-02,\n",
            "        -7.11661354e-02, -5.40183783e-02, -3.02508660e-02,\n",
            "        -7.13177100e-02,  1.38521492e-01, -2.97327161e-01,\n",
            "        -6.11300133e-02,  9.06619877e-02,  7.03536123e-02,\n",
            "        -1.99713819e-02, -3.18571553e-02, -9.68682766e-02,\n",
            "        -5.60845360e-02,  7.33937100e-02, -1.80228248e-01,\n",
            "         6.16034195e-02,  1.29134376e-02, -1.95577964e-02,\n",
            "        -3.67361046e-02,  2.09450006e-01,  6.21005297e-02,\n",
            "         9.02430434e-03,  2.97245625e-02, -7.61567205e-02,\n",
            "        -9.93321985e-02,  1.13361359e-01, -4.33227271e-02,\n",
            "         2.08972041e-02,  6.68266490e-02,  1.47553593e-01,\n",
            "         5.60244098e-02,  1.08817413e-01,  2.39764094e-01,\n",
            "        -2.65388377e-02, -2.02290311e-01, -1.56640112e-02,\n",
            "        -3.04264128e-02, -1.20682426e-01,  1.23266742e-01,\n",
            "        -3.46485749e-02, -3.50511447e-03, -2.40559503e-03,\n",
            "        -1.54038504e-01,  1.61792785e-02,  3.04900929e-02,\n",
            "         1.00309756e-02, -7.41563737e-02, -5.10001332e-02,\n",
            "         6.00282289e-02, -2.15949401e-01,  1.40149802e-01,\n",
            "        -4.87450883e-02,  1.24284066e-01,  1.01379089e-01,\n",
            "         2.04559520e-01, -1.02721117e-02, -5.46306483e-02,\n",
            "         9.85879358e-03, -3.91355343e-03,  1.06905028e-01,\n",
            "         3.21966968e-02, -6.57170862e-02,  8.93279240e-02,\n",
            "        -2.16307491e-02,  1.62239552e-01, -1.51230797e-01,\n",
            "        -5.10149635e-04,  1.07166514e-01,  9.92179513e-02,\n",
            "         1.35717422e-01,  1.85322702e-01, -1.04070023e-01,\n",
            "        -6.28011450e-02, -7.40795583e-03,  1.87881030e-02,\n",
            "        -4.55697626e-02,  5.09505756e-02, -1.29579201e-01,\n",
            "         4.44659255e-02, -3.39856446e-02, -1.85639858e-01,\n",
            "        -3.31535712e-02, -1.25734687e-01, -2.95875054e-02,\n",
            "         3.55158746e-02, -1.06897563e-01,  2.29606405e-02,\n",
            "         5.76179400e-02,  6.65735751e-02, -2.33923942e-01,\n",
            "        -1.37848794e-01, -1.93237979e-02, -1.75464246e-02,\n",
            "        -1.41354129e-01, -1.53704107e-01, -1.35133535e-01,\n",
            "         6.82181567e-02,  2.18688071e-01,  2.45077349e-02,\n",
            "        -1.27616934e-02, -5.49490601e-02,  2.73063444e-02,\n",
            "         2.18119323e-02, -8.43358561e-02, -6.96708560e-02,\n",
            "        -8.11257660e-02, -5.02905622e-02,  8.63674283e-02,\n",
            "         1.98900085e-02, -3.92948352e-02,  6.05796352e-02,\n",
            "         3.26486602e-02,  3.02938282e-01, -2.82786787e-01,\n",
            "         1.72846895e-02,  3.40199053e-01,  7.11913854e-02,\n",
            "         2.64827553e-02, -1.36036038e-01, -5.38873486e-02,\n",
            "        -6.17457964e-02,  1.69854879e-01, -5.65529987e-03,\n",
            "         3.28273252e-02,  6.67639822e-02,  4.77574132e-02,\n",
            "         4.41102907e-02, -1.29408687e-01,  1.02559716e-01,\n",
            "         3.01821977e-02,  9.77225602e-03,  9.81198400e-02,\n",
            "         1.13178194e-01,  5.26851006e-02, -9.49893296e-02,\n",
            "        -8.17792118e-02,  2.09500015e-01,  3.64417061e-02,\n",
            "        -3.92251313e-02, -5.79985715e-02, -7.55182654e-02,\n",
            "        -1.22354455e-01,  5.18512875e-02,  1.06913701e-01,\n",
            "        -8.13641772e-02, -2.41218377e-02,  5.76690100e-02,\n",
            "         9.21158940e-02,  3.59846205e-02,  4.65499386e-02,\n",
            "         7.36014172e-02,  8.07580166e-03, -1.64465696e-01,\n",
            "        -1.66128337e-01,  9.73775983e-03, -1.05153546e-02,\n",
            "        -2.57784240e-02, -9.96129811e-02,  3.09698842e-03,\n",
            "        -6.23020455e-02, -4.89379354e-02,  6.86999857e-02,\n",
            "        -1.54851183e-01, -4.70048264e-02,  2.02843435e-02,\n",
            "         5.12786582e-03,  1.20206997e-01, -1.19721897e-01,\n",
            "        -9.78391618e-02,  6.86359406e-02, -1.52906388e-01,\n",
            "         5.38179427e-02,  7.82842487e-02, -1.31565303e-01,\n",
            "        -7.86749125e-02,  1.02743551e-01, -1.03439108e-01,\n",
            "         2.38197893e-02, -4.05984651e-03,  6.88222945e-02,\n",
            "         7.95472786e-02,  7.02935904e-02,  6.77257329e-02,\n",
            "         1.19205728e-01,  8.38170946e-03,  7.41574392e-02,\n",
            "        -8.92849267e-03]], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_5QksaR2NJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab841e0-5f53-4945-8ae5-d78296cafa29"
      },
      "source": [
        "#Calculating the Cosine Similarity between Vectors of Words.\n",
        "\n",
        "print(\"Similarity between Paris-France+Italy and Rome:\",cosine_similarity(X1,d1))\n",
        "print(\"Similarity between France-Paris+Italy and Rome:\",cosine_similarity(Y1,d1))\n",
        "print(\"Similarity between France and Italy:\",cosine_similarity(b1,c1))\n",
        "print(\"Similarity between Paris and Rome:\",cosine_similarity(a1,d1))\n",
        "print(\"Similarity between France and Paris:\",cosine_similarity(b1,a1))\n",
        "print(\"Similarity between Italy and Rome:\",cosine_similarity(c1,d1))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity between Paris-France+Italy and Rome: [[0.7295018]]\n",
            "Similarity between France-Paris+Italy and Rome: [[0.7537309]]\n",
            "Similarity between France and Italy: [[0.6112312]]\n",
            "Similarity between Paris and Rome: [[0.5107142]]\n",
            "Similarity between France and Paris: [[0.74734336]]\n",
            "Similarity between Italy and Rome: [[0.7058664]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHXlmu39Ce4J"
      },
      "source": [
        "# Creating list of words similar to dog\n",
        "dog_related_words = ['canine','doggy','pooch','hound','tyke','pup','puppy','cur','mongrel','mutt','watchdog','bitch','sheepdog','hunter','bandog','whelp']"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v9f6BPRLVfx"
      },
      "source": [
        "# Embedding all the words in the list similar to dog\n",
        "embedder = []\n",
        "for i in range(len(dog_related_words)):\n",
        "  embedder.append(embedding([dog_related_words[i]]))\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHyqQa5tLcOf"
      },
      "source": [
        "# Embedding Dog word\n",
        "dog_embedder = embedding(['dog'])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLFFO1T4MZ7q"
      },
      "source": [
        "similarity = {}\n",
        "for i in range(len(embedder)):\n",
        "  similarity[dog_related_words[i]] = cosine_similarity(dog_embedder,embedder[i])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3m2KJI5NIL1",
        "outputId": "986e2f56-819e-461b-ca87-eb17766c5a20"
      },
      "source": [
        "# Sorting the dictionary based on the similarity value in ascending\n",
        "sorted_similarity = {}\n",
        "sorted_values = sorted(similarity.values())\n",
        "for i in sorted_values:\n",
        "    for k in similarity.keys():\n",
        "        if similarity[k] == i:\n",
        "            sorted_similarity[k] = similarity[k]\n",
        "            break\n",
        "\n",
        "print(sorted_similarity)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bandog': array([[0.]], dtype=float32), 'watchdog': array([[0.07606272]], dtype=float32), 'cur': array([[0.3497349]], dtype=float32), 'whelp': array([[0.45355585]], dtype=float32), 'mutt': array([[0.49267846]], dtype=float32), 'bitch': array([[0.50176835]], dtype=float32), 'pooch': array([[0.51102823]], dtype=float32), 'hunter': array([[0.5172389]], dtype=float32), 'tyke': array([[0.55394626]], dtype=float32), 'canine': array([[0.6049171]], dtype=float32), 'doggy': array([[0.6388842]], dtype=float32), 'mongrel': array([[0.68380666]], dtype=float32), 'pup': array([[0.6987275]], dtype=float32), 'hound': array([[0.78350145]], dtype=float32), 'sheepdog': array([[0.78973323]], dtype=float32), 'puppy': array([[0.8488173]], dtype=float32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN3owLLzO416",
        "outputId": "a99a4419-697e-4c15-a2b6-885e270a0066"
      },
      "source": [
        "# Printing top 5 words closest to dog\n",
        "length = len(list(sorted_similarity))\n",
        "print(length)\n",
        "key = list(sorted_similarity.keys())\n",
        "for i in range(length):\n",
        "  if i<(length-5):\n",
        "    continue\n",
        "  else:\n",
        "    print(\"Word :\", key[i])\n",
        "    print(\"Cosine Similarity :\", sorted_similarity[key[i]])  \n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "Word : mongrel\n",
            "Cosine Similarity : [[0.68380666]]\n",
            "Word : pup\n",
            "Cosine Similarity : [[0.6987275]]\n",
            "Word : hound\n",
            "Cosine Similarity : [[0.78350145]]\n",
            "Word : sheepdog\n",
            "Cosine Similarity : [[0.78973323]]\n",
            "Word : puppy\n",
            "Cosine Similarity : [[0.8488173]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkrlj4XoPM9B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}